# Probability-Statistics-for-Machine-Learning-Data-Science

This course is part of the [Mathematics for Machine Learning and Data Science Specialization](https://www.deeplearning.ai/courses/mathematics-for-machine-learning-and-data-science-specialization/) by [DeepLearning.AI](https://www.deeplearning.ai).

After completing this course, learners will be able to:
- Analytically optimize different types of functions commonly used in machine learning using properties of derivatives and gradients 
- Approximately optimize different types of functions commonly used in machine learning using first-order (gradient descent) and second-order (Newtonâ€™s method) iterative methods
- Visually interpret differentiation of different types of functions commonly used in machine learning
- Perform gradient descent in neural networks with different activation and cost functions 

### Week 1: Introduction to probability and random variables

#### Lesson 1: Introduction to probability
- Concept of probability: repeated random trials
- Conditional probability and independence
- Discriminative learning and conditional probability
- Bayes theorem
- Lab: Four Birthday Problems
- Lab: Monty Hall Problem
- Practice Quiz

#### Lesson 2: Random variables
- Random variables
- Cumulative distribution function
- Discrete random variables: Bernoulli distribution
- Discrete random variables: Binomial distribution
- Probability mass function
- Continuous random variables: Uniform distribution
- Continuous random variables: Gaussian distribution
- Continuous random variables: Chi squared distribution
- Probability distribution function
- Quiz
- Programming Assignment: Probability Distributions / Naive Bayes

### Week 2: Describing distributions and random vectors

#### Lesson 1: Describing distributions
- Measures of central tendency: mean, median, mode
- Expected values
- Quantiles and box-plots
- Measures of dispersion: variance, standard deviation
- Practice Quiz

#### Lesson 2: Random vectors
- Joint distributions
- Marginal and conditional distributions
- Independence
- Measures of relatedness: covariance
- Multivariate normal distribution
- Lab: Summary statistics and visualization of data sets
- Quiz
- Lab: Simulating Dice Rolls with Numpy
- Programming Assignment: Loaded Dice

### Week 3: Introduction to statistics

#### Lesson 1: Sampling and point estimates
- Population vs. sample
- Describing samples: sample proportion and sample mean
- Distribution of sample mean and proportion: Central Limit Theorem
- Point estimates
- Biased vs Unbiased estimates
- Lab: Sampling data from different distribution and studying the distribution of sample mean
- Practice Quiz

#### Lesson 2: Maximum likelihood estimation
- ML motivation example: Linear Discriminant Analysis
- Likelihood
- Intuition behind maximum likelihood estimation
- MLE: How to get the maximum using calculus

#### Lesson 3: Bayesian statistics
- ML motivation example: Naive Bayes
- Frequentist vs. Bayesian statistics
- A priori/ a posteriori distributions
- Bayesian estimators: posterior mean, posterior median, MAP
- Quiz

### Week 4: Interval statistics and Hypothesis testing

#### Lesson 1: Confidence intervals
- Margin of error
- Interval estimation
- Confidence Interval for mean of population
- CI for parameters in linear regression
- Prediction Interval
- Practice Quiz

#### Lesson 2: Hypothesis testing
- ML Motivation: AB Testing
- Criminal trial
- Two types of errors
- Test for proportion and means
- Two sample inference for difference between groups
- ANOVA
- Power of a test
- Quiz
- Programming Assignment: A/B Testing
